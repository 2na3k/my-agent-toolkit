# AI Provider Configuration
providers:
  claude:
    base_url: "https://api.anthropic.com/v1/"
    default_model: "claude-sonnet-4-5"
    models:
      - "claude-sonnet-4-5"
      - "claude-opus-4"
      - "claude-haiku-3-5"
    timeout: 60
    max_retries: 3

  gemini:
    base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
    default_model: "gemini-3-flash-preview"
    models:
      - "gemini-3-flash-preview"
      - "gemini-2.0-flash-exp"
    timeout: 60
    max_retries: 3

  openai:
    base_url: "https://api.openai.com/v1/"
    default_model: "gpt-4o"
    models:
      - "gpt-4o"
      - "gpt-4o-mini"
      - "gpt-4-turbo"
    timeout: 60
    max_retries: 3

  # Custom local providers (examples)
  ollama:
    base_url: "http://localhost:11434/v1/"
    default_model: "qwen2.5:latest"
    models:
      - "qwen2.5:latest"
      - "llama3.2:latest"
      - "mistral:latest"
      - "phi3:latest"
    timeout: 120
    max_retries: 2
    requires_api_key: false  # Local provider, no API key needed
    default_api_key: "not-needed"  # Dummy key for OpenAI SDK compatibility

  llamacpp:
    base_url: "http://localhost:8080/v1/"
    default_model: "local-model"
    models:
      - "local-model"
    timeout: 120
    max_retries: 2
    requires_api_key: false  # Local provider, no API key needed
    default_api_key: "not-needed"  # Dummy key for OpenAI SDK compatibility

  # LM Studio (another popular local option)
  lmstudio:
    base_url: "http://localhost:1234/v1/"
    default_model: "local-model"
    models:
      - "local-model"
    timeout: 120
    max_retries: 2
    requires_api_key: false
    default_api_key: "not-needed"

# Default provider to use
default_provider: "gemini"

# Global settings
settings:
  temperature: 0.7
  max_tokens: 4096
  stream: false
